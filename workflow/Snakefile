from snakemake.utils import validate
import pandas as pd
import os
import string

##### load config #####

configfile: "config/config.yaml"

##### functions #####

def _get_sample_file(wildcards, table, extension):
    m = pd.read_csv(table, sep='\t', index_col=0)
    return m.loc[wildcards.sample, extension]

def _get_all_samples(table):
    m = pd.read_csv(table, sep='\t', index_col=0)
    return m.index

# used to generate a pseudorandom but persistent
# folder name for temporary files
username = os.getenv('USER')
if username is None:
    username = 'gwas'

##### rules #####

rule unitigs:
  input: config["unitigs_input"]
  output:
    config["unitigs"],
    config["unitigs_rtab"]
  params: config["unitigs_dir"]
  threads: 16
  conda: "envs/unitig-counter.yaml"
  log: "out/logs/unitigs.log"
  shell:
    """
    rm -rf {params} && \
    unitig-counter -strains {input} -output {params} \
    -gzip -nb-cores {threads} 2> {log}
    """

rule lineage_st:
  input: config["mash_input"]
  output: config["lineage_mlst"]
  params:
    scheme=config["mlst_scheme"],
    tmp="/tmp/mlst_" + username
  threads: 16
  conda: "envs/mlst.yaml"
  log: "out/logs/mlst.log"
  shell:
    """
    mkdir -p {params.tmp} 2> {log}
    for i in $(cat {input}); do echo "mlst --scheme {params.scheme} --threads 1 "$i" | cut -f1,3 > {params.tmp}/"$(basename $i)".mlst"; done > {params.tmp}/mlst_jobs.txt 2>> {log}
    parallel -j {threads} --progress < {params.tmp}/mlst_jobs.txt 2>> {log}
    cat {params.tmp}/*.mlst > {params.tmp}/all_mlst.txt 2>> {log}
    python workflow/scripts/sanitize_mlst.py {params.tmp}/all_mlst.txt > {output} 2>> {log}
    rm -rf {params.tmp} 2>> {log}
    """

rule lineage_poppunk:
  input: config["poppunk_input"]
  output: config["lineage_poppunk"]
  params:
    indir=config["poppunk_db"],
    outdir=config["poppunk_dir"]
  threads: 16
  conda: "envs/poppunk.yaml"
  log: "out/logs/poppunk.log"
  shell:
     """
     poppunk_assign --db {params.indir} \
             --query {input} --output {params.outdir} \
             --threads {threads} 2> {log} && \
     tail -n+2 {params.outdir}/poppunk_clusters.csv | \
     sed 's/data\/fastas\///g' | sed 's/.fasta//g' | \
     awk -F',' '{{print $1"\\t"$2}}' > {output}
     """

rule find_amr_vag:
  input: config["unitigs_input"]
  output:
    "out/abritamr/abritamr.txt"
  params:
    species=config["species_amr"]
  threads: 36
  conda: "envs/abritamr.yaml"
  log: "out/logs/find_amr_vag.log"
  shell:
    """
    mkdir -p out/abritamr && \
    tail -n+2 {input} | awk -v OFS='\t' '{{ cmd="realpath " $2; cmd | getline $2; close(cmd); print }}' > out/abritamr/abritamr_input.tsv 2> {log} && \
    cd out/abritamr && \
    abritamr run --contigs abritamr_input.tsv --species {params.species} --jobs {threads} 2>> ../../{log}
    """

rule mash_sketch:
  input: config["mash_input"]
  output: config["sketches"]
  params: config["sketches_base"]
  threads: 5
  conda: "envs/mash.yaml"
  log: "out/logs/mash_sketch.log"
  shell:
    "mash sketch -p {threads} -s 10000 -o {params} -l {input} 2> {log}"

rule distance:
  input: config["sketches"]
  output: config["distances"]
  threads: 5
  conda: "envs/mash.yaml"
  log: "out/logs/distance.log"
  shell:
    "mash dist -p {threads} {input} {input} | square_mash > {output} 2> {log}"

rule pangenome:
  input: config["panaroo_input"]
  output:
    rtab=config["pangenome"],
    csv=config["pangenome_csv"],
    genes=config["pangenome_genes"],
    struct=config["structural"],
    aln=config["core_genome_aln"]
  params:
    final=config["panaroo_dir"],
    tmp=config["panaroo_dir_tmp"]
  threads: 24
  conda: "envs/panaroo.yaml"
  log: "out/logs/pangenome.log"
  shell:
    """
    panaroo -t {threads} -i {input} -o {params.tmp} --clean-mode strict -a core 2> {log}
    mkdir -p {params.final}
    mv {params.tmp}/gene_presence_absence.Rtab {params.final}
    mv {params.tmp}/gene_presence_absence.csv {params.final}
    mv {params.tmp}/gene_data.csv {params.final}
    mv {params.tmp}/struct_presence_absence.Rtab {params.final}
    mv {params.tmp}/core_gene_alignment.aln {params.final}
    rm -rf {params.tmp}
    """

rule variant_sites:
  input: config["core_genome_aln"]
  output: config["core_genome_aln_variant"]
  conda: "envs/snp-sites.yaml"
  log: "out/logs/variant_sites.log"
  shell:
    "snp-sites -o {output} {input} 2> {log}"

rule aln2vcf:
  input: config["core_genome_aln"]
  output: config["core_genome_vcf"]
  conda: "envs/snp-sites.yaml"
  threads: 16
  log: "out/logs/snp-sites.log"
  shell:
    """
    snp-sites -o core.vcf -v {input}
    bcftools norm -m - -O z --threads {threads} core.vcf > {output} 2> {log}
    bcftools index {output}
    rm core.vcf
    """

rule similarity:
  input:
    aln=config["core_genome_aln"],
    vcf=config["core_genome_vcf"]
  output: config["similarities"]
  conda: "envs/pyseer.yaml"
  log: "out/logs/similarity.log"
  shell:
    """
    grep '>' {input.aln} | cut -c 2- > similarity_samples.txt
    python workflow/scripts/similarity.py similarity_samples.txt \
           --vcf {input.vcf} \
           > {output} 2> {log}
    rm similarity_samples.txt
    """

rule tree:
  input: config["core_genome_aln"]
  output: config["tree"]
  conda: "envs/fasttree.yaml"
  log: "out/logs/tree.log"
  shell:
    "FastTree -nt -gtr < {input} > {output} 2> {log}"

rule prepare_pyseer:
  input:
    variants=config["unitigs_input"],
    phenotypes=config["samples"],
    similarity=config["similarities"],
    distances=config["distances"],
    lineage=config["lineages_file"]
  output:
    phenotypes=os.path.join(config["association_inputs"], "{phenotype}/phenotypes.tsv"),
    similarity=os.path.join(config["association_inputs"], "{phenotype}/similarity.tsv"),
    distances=os.path.join(config["association_inputs"], "{phenotype}/distances.tsv"),
    lineage=os.path.join(config["association_inputs"], "{phenotype}/lineages.tsv")
  params: os.path.join(config["association_inputs"], "{phenotype}")
  log: "out/logs/prepare_pyseer_{phenotype}.log"
  shell:
    "python workflow/scripts/prepare_pyseer.py {input} {params} {wildcards.phenotype} 2> {log}"

rule prepare_wg:
  input:
    variants=config["unitigs_input"],
    unitigs=config["unitigs"],
    phenotypes=config["samples"],
    similarity=config["similarities"],
    distances=config["distances"],
    lineage=config["lineages_file"]
  output:
    phenotypes=os.path.join(config["wg_inputs"], "{phenotype}/phenotypes.tsv"),
    similarity=os.path.join(config["wg_inputs"], "{phenotype}/similarity.tsv"),
    distances=os.path.join(config["wg_inputs"], "{phenotype}/distances.tsv"),
    lineage=os.path.join(config["wg_inputs"], "{phenotype}/lineages.tsv"),
    variants=os.path.join(config["wg_inputs"], "{phenotype}/variants.pkl")
  params:
    directory=os.path.join(config["wg_inputs"], "{phenotype}"),
    variants=os.path.join(config["wg_inputs"], "{phenotype}/variants"),
    covariates=lambda wildcards: config.get("covariates", {wildcards.phenotype: ''})[wildcards.phenotype]
  threads: 4
  conda: "envs/pyseer.yaml"
  log: "out/logs/prepare_wg_{phenotype}.log"
  shell:
    """
     python workflow/scripts/prepare_pyseer.py {input.variants} {input.phenotypes} \
                                                {input.similarity} {input.distances} \
                                                {input.lineage} {params.directory} \
                                                {wildcards.phenotype} 2> {log} && \
     pyseer --phenotypes {output.phenotypes} --phenotype-column {wildcards.phenotype} \
            --kmers {input.unitigs} \
            --wg enet --save-vars {params.variants} \
            --cor-filter 0.0 \
            {params.covariates} \
            --cpu {threads} > /dev/null 2>> {log}
    """

rule heritability:
  input:
    expand('out/associations/{target}/heritability_all.tsv',
           target=config["targets"])

rule lineages2covariance:
  input:
    os.path.join(config["association_inputs"], "{target}/lineages.tsv")
  output:
    os.path.join(config["association_inputs"], "{target}/lineages_covariance.tsv")
  log: "out/logs/lineages2covariance_{target}.log"
  shell:
    "python workflow/scripts/lineage2covar.py {input} > {output} 2> {log}"

rule run_heritability:
  input:
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    similarity=os.path.join(config["association_inputs"], "{target}/similarity.tsv"),
    lineages=os.path.join(config["association_inputs"], "{target}/lineages_covariance.tsv"),
  output:
    h_ci="out/associations/{target}/heritability.ci.tsv",
    h="out/associations/{target}/heritability.tsv",
    h_lineages="out/associations/{target}/heritability_lineages.tsv",
  conda: "envs/limix.yaml"
  log: "out/logs/heritability_{target}.log"
  shell:
    """
    python workflow/scripts/estimate_heritability.py {input.phenotypes} {input.similarity} \
          -p {wildcards.target} \
    > {output.h} 2> {log}
    tempfile=$(mktemp) && \
    python workflow/scripts/prepare_fiesta.py {input.phenotypes} {input.similarity} \
          -p {wildcards.target} \
          --prefix $tempfile 2>> {log} && \
    grep normal {output.h} | awk '{{print $3}}' > $tempfile".estimates.txt" && \
    grep normal {output.h} | awk '{{print $3}}' >> $tempfile".estimates.txt" && \
    python albi/albi.py -k $tempfile"_values.txt" \
          -f $tempfile".estimates.txt" 2>> {log} \
    | grep -v "Estimating" | grep -v '#' > {output.h_ci} || true

    python workflow/scripts/estimate_heritability.py {input.phenotypes} {input.lineages} \
          -p {wildcards.target} \
    > {output.h_lineages} 2>> {log}
    tempfile=$(mktemp) && \
    python workflow/scripts/prepare_fiesta.py {input.phenotypes} {input.lineages} \
          -p {wildcards.target} \
          --prefix $tempfile 2>> {log} && \
    grep normal {output.h_lineages} | awk '{{print $3}}' > $tempfile".estimates.txt" && \
    grep normal {output.h_lineages} | awk '{{print $3}}' >> $tempfile".estimates.txt" && \
    python albi/albi.py -k /tmp/{wildcards.target}_values.txt \
          -f $tempfile".estimates.txt" 2>> {log} \
    | grep -v "Estimat" | grep -v '#' >> {output.h_ci} || true
    """

rule combine_heritability:
  input:
    h_ci="out/associations/{target}/heritability.ci.tsv",
    h="out/associations/{target}/heritability.tsv",
    h_lineages="out/associations/{target}/heritability_lineages.tsv",
  output:
    "out/associations/{target}/heritability_all.tsv"
  log: "out/logs/combine_heritability_{target}.log"
  shell:
    "python workflow/scripts/combine_heritability.py {input.h} {input.h_lineages} {input.h_ci} > {output} 2> {log}"

rule download_sequence_unet:
  output: os.path.join(config["sequence_unet"], "freq_classifier.tf/saved_model.pb")
  params: config["sequence_unet"]
  conda: "envs/sequence_unet.yaml"
  log: "out/logs/download_sequence_unet.log"
  shell:
    "python workflow/scripts/download_sequence_unet_model.py {params} 2> {log}"

rule sequence_unet:
  input:
    model=os.path.join(config["sequence_unet"], "freq_classifier.tf/saved_model.pb"),
    reference=config["snps_reference_faa"]
  output: "out/snps/unet/unet.done"
  params:
    model=config["sequence_unet"],
    outdir=config["unet"]
  threads: 8
  conda: "envs/sequence_unet.yaml"
  log: "out/logs/sequence_unet.log"
  shell:
    """
    python workflow/scripts/sequence_unet_predictions.py --fasta {input.reference} \
           --model_dir {params.model} --output {params.outdir} --cores {threads} \
           freq_classifier 2> {log} && \
    touch {output}
    """

rule prepare_rare_variants:
  input:
    vcf=config["bcftools_input"],
    unet="out/snps/unet/unet.done",
    snps="out/snps/snps.done"
  output: config["rare_snps"]
  params: config["unet"]
  threads: 36
  conda: "envs/bcftools.yaml"
  log: "out/logs/prepare_rare_variants.log"
  shell:
    """
    bcftools merge -l {input.vcf} -0 -O z --threads {threads} > out/snps/merged.vcf.gz 2> {log}
    bcftools norm -m - -O z --threads {threads} out/snps/merged.vcf.gz > out/snps/norm.vcf.gz 2>> {log}
    bcftools view -Q 0.05 out/snps/norm.vcf.gz -O z --threads {threads} > out/snps/filtered.vcf.gz 2>> {log}
    python workflow/scripts/vcf2deleterious.py out/snps/filtered.vcf.gz --unet {params} | bgzip > {output} 2>> {log}
    bcftools index {output} 2>> {log}
    rm out/snps/merged.vcf.gz out/snps/norm.vcf.gz out/snps/filtered.vcf.gz
    """

rule snps:
  input:
    expand("out/snps/{sample}/snps.vcf.gz",
           sample=_get_all_samples(config["samples"]))
  output: "out/snps/snps.done"
  shell: "touch {output}"

rule get_snps:
  input:
    ref=config["snps_reference"],
    ctgs=lambda wildcards: _get_sample_file(wildcards, config["samples"], 'fasta')
  output:
    "out/snps/{sample}/snps.vcf.gz"
  params:
    final="out/snps/{sample}",
    tmp=os.path.join(config["snippy_dir_tmp"], "{sample}")
  conda: "envs/nucmer.yaml"
  log: "out/logs/snippy_{sample}.log"
  shell:
    """
    snippy --force --outdir {params.tmp} --ref {input.ref} --ctgs {input.ctgs} --cpus 1 --ram 8 2> {log}
    mkdir -p {params.final}
    mv {params.tmp}/snps.vcf.gz {params.final}/
    mv {params.tmp}/snps.vcf.gz.csi {params.final}/
    rm -rf {params.tmp}
    """

rule prepare_regions:
  input: config["snps_reference_gff"],
  output: config["regions"]
  shell:
    """
    grep CDS {input} | \
    awk -F '\t' '{{print $1":"$4"-"$5"\t"$9}}' | \
    sed 's/.1:/:/g' | awk -F ';' '{{print $1}}' | \
    sed 's/ID=//g' | awk '{{print $2"\t"$1}}' > {output}
    """

rule pyseer:
  input:
    expand('out/associations/{target}/unitigs_filtered.tsv',
           target=config["targets"]),
    expand('out/associations/{target}/gpa_summary.tsv',
           target=config["targets"])

rule pyseer_rare:
  input:
    expand('out/associations/{target}/rare_summary.tsv',
           target=config["targets"])

rule wg:
  input:
    expand('out/wg/{target}/ridge.tsv',
           target=config["targets"]),
    expand('out/wg/{target}/lasso.tsv',
           target=config["targets"]),

rule run_pyseer:
  input:
    unitigs=config["unitigs"],
    gpa=config["pangenome"],
    struct=config["structural"],
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    similarity=os.path.join(config["association_inputs"], "{target}/similarity.tsv"),
    distances=os.path.join(config["association_inputs"], "{target}/distances.tsv"),
    lineages=os.path.join(config["association_inputs"], "{target}/lineages.tsv")
  output:
    patterns="out/associations/{target}/unitigs_patterns.txt",
    unitigs="out/associations/{target}/unitigs.tsv",
    unitigs_f="out/associations/{target}/unitigs_filtered.tsv",
    gpa="out/associations/{target}/gpa.tsv",
    gpa_f="out/associations/{target}/gpa_filtered.tsv",
    struct="out/associations/{target}/struct.tsv",
    struct_f="out/associations/{target}/struct_filtered.tsv"
  params:
    covariates=lambda wildcards: config.get("covariates", {wildcards.target: ''})[wildcards.target]
  threads: 2
  conda: "envs/pyseer.yaml"
  log: "out/logs/pyseer_{target}.log"
  shell:
    """
    zcat {input.unitigs} | head -n 10 > out/associations/{wildcards.target}/small.txt || true
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --kmers out/associations/{wildcards.target}/small.txt \
           --uncompressed \
           --cpu {threads} \
           --lineage --lineage-clusters {input.lineages} \
           --lineage-file out/associations/{wildcards.target}/unitigs_lineage.txt \
           --distances {input.distances} \
           {params.covariates} \
           > /dev/null 2> {log}
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --kmers {input.unitigs} \
           --similarity {input.similarity} \
           --lmm \
           --output-patterns out/associations/{wildcards.target}/unitigs_patterns.txt \
           --cpu {threads} \
           {params.covariates} \
           > {output.unitigs} 2>> {log} && \
    sleep 5 && \
    cat <(head -1 {output.unitigs}) <(LC_ALL=C awk -v pval=$(python workflow/scripts/count_patterns.py --threshold out/associations/{wildcards.target}/unitigs_patterns.txt) '$4<pval {{print $0}}' {output.unitigs}) > {output.unitigs_f}
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --pres {input.gpa} \
           --similarity {input.similarity} \
           --lmm --uncompressed \
           --output-patterns out/associations/{wildcards.target}/gpa_patterns.txt \
           --cpu {threads} \
           {params.covariates} \
           > {output.gpa} 2>> {log} && \
    sleep 5 && \
    cat <(head -1 {output.gpa}) <(LC_ALL=C awk -v pval=$(python workflow/scripts/count_patterns.py --threshold out/associations/{wildcards.target}/unitigs_patterns.txt) '$4<pval {{print $0}}' {output.gpa}) > {output.gpa_f}
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --pres {input.struct} \
           --similarity {input.similarity} \
           --lmm --uncompressed \
           --output-patterns out/associations/{wildcards.target}/struct_patterns.txt \
           --cpu {threads} \
           {params.covariates} \
           > {output.struct} 2>> {log} && \
    sleep 5 && \
    cat <(head -1 {output.struct}) <(LC_ALL=C awk -v pval=$(python workflow/scripts/count_patterns.py --threshold out/associations/{wildcards.target}/unitigs_patterns.txt) '$4<pval {{print $0}}' {output.struct}) > {output.struct_f}
    """

rule run_gpa_summary:
  input:
    filtered="out/associations/{target}/gpa_filtered.tsv",
    pangenome=config["pangenome"],
    pangenome2=config["pangenome_csv"],
  output:
    summary="out/associations/{target}/gpa_summary.tsv"
  params:
    d=config["references_gffs"],
    r=config["summary_references"]
  log: "out/logs/gpa_summary_{target}.log"
  shell:
    """
    python workflow/scripts/gpa_summary.py {input.filtered} \
           --pangenome {input.pangenome} \
           --pangenome-genes {input.pangenome2} \
           {params.r} \
           --gff-dir {params.d} \
           --sort lrt-pvalue \
           > {output.summary} 2> {log} || true
    """

rule run_pyseer_rare:
  input:
    snps=config["rare_snps"],
    regions=config["regions"],
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    similarity=os.path.join(config["association_inputs"], "{target}/similarity.tsv"),
    lineages=os.path.join(config["association_inputs"], "{target}/lineages.tsv"),
    patterns="out/associations/{target}/unitigs_patterns.txt",
  output:
    rare="out/associations/{target}/rare.tsv",
    rare_f="out/associations/{target}/rare_filtered.tsv",
  params:
    covariates=lambda wildcards: config.get("covariates", {wildcards.target: ''})[wildcards.target]
  conda: "envs/pyseer.yaml"
  log: "out/logs/pyseer_rare_{target}.log"
  shell:
    """
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --vcf {input.snps} \
           --burden {input.regions} \
           --similarity {input.similarity} \
           --lmm \
           --output-patterns out/associations/{wildcards.target}/rare_patterns.txt \
           --cpu 1 \
           {params.covariates} \
           > {output.rare} 2> {log} && \
    cat <(head -1 {output.rare}) <(LC_ALL=C awk -v pval=$(python workflow/scripts/count_patterns.py --threshold {input.patterns}) '$4<pval {{print $0}}' {output.rare}) > {output.rare_f}
    """

rule run_rare_summary:
  input:
    filtered="out/associations/{target}/rare_filtered.tsv",
    pangenome=config["pangenome"],
    pangenome2=config["pangenome_csv"],
  output:
    summary="out/associations/{target}/rare_summary.tsv"
  params:
    d=config["references_gffs"],
    r=config["summary_references"],
    ref=config["enrichment_reference"]
  log: "out/logs/rare_summary_{target}.log"
  shell:
    """
    python workflow/scripts/rare_summary.py {input.filtered} {params.ref} \
           --pangenome {input.pangenome} \
           --pangenome-genes {input.pangenome2} \
           {params.r} \
           --gff-dir {params.d} \
           --sort lrt-pvalue \
           > {output.summary} 2> {log} || true
    """

rule qq_plots:
  input:
    expand('out/associations/{target}/qq_{variant}.png',
           target=config["targets"],
           variant=["unitigs", "gpa", "rare"]),

rule run_qq_plot:
  input: "out/associations/{target}/{variant}.tsv"
  output: "out/associations/{target}/qq_{variant}.png"
  conda: "envs/pyseer.yaml"
  log: "out/logs/qq_{variant}_{target}.log"
  shell: "python workflow/scripts/qq_plot.py {input} --output {output} 2> {log}"

rule run_wg:
  input:
    unitigs=config["unitigs"],
    variants=os.path.join(config["wg_inputs"], "{target}/variants.pkl"),
    phenotypes=os.path.join(config["wg_inputs"], "{target}/phenotypes.tsv"),
    similarity=os.path.join(config["wg_inputs"], "{target}/similarity.tsv"),
    distances=os.path.join(config["wg_inputs"], "{target}/distances.tsv"),
    lineages=os.path.join(config["wg_inputs"], "{target}/lineages.tsv")
  output:
    ridge="out/wg/{target}/ridge.tsv",
    ridge_o="out/wg/{target}/ridge.txt",
    ridge_m="out/wg/{target}/ridge.pkl",
    lasso="out/wg/{target}/lasso.tsv",
    lasso_o="out/wg/{target}/lasso.txt",
    lasso_m="out/wg/{target}/lasso.pkl",
  params:
    variants = os.path.join(config["wg_inputs"], "{target}/variants"),
    ridge = "out/wg/{target}/ridge",
    lasso = "out/wg/{target}/lasso",
    covariates=lambda wildcards: config.get("covariates", {wildcards.target: ''})[wildcards.target]
  threads: 4
  conda: "envs/pyseer.yaml"
  shell:
    """
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --kmers {input.unitigs} \
           --distances {input.distances} \
           --wg enet \
           --load-vars {params.variants} \
           --save-model {params.ridge} \
           --alpha 0.01 \
           --sequence-reweighting \
           --lineage-clusters {input.lineages} \
           --cor-filter 0.0 \
           {params.covariates} \
           > {output.ridge} 2> {output.ridge_o}
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --kmers {input.unitigs} \
           --distances {input.distances} \
           --wg enet \
           --load-vars {params.variants} \
           --save-model {params.lasso} \
           --alpha 1 \
           --sequence-reweighting \
           --lineage-clusters {input.lineages} \
           --cor-filter 0.0 \
           {params.covariates} \
           > {output.lasso} 2> {output.lasso_o}
    """

rule map_back:
  input:
    expand("out/associations/{target}/mapped.tsv",
           target=config["targets"]),
    expand("out/associations/{target}/mapped_all.tsv",
           target=config["targets"]),
    expand("out/wg/{target}/mapped_{model}.tsv",
           target=config["targets"],
           model=['ridge', 'lasso']),

rule run_map_back:
  input:
    unitigs="out/associations/{target}/unitigs_filtered.tsv",
    fasta=config["mash_input"],
    gff=config["panaroo_input"],
    pangenome=config['pangenome_csv']
  output:
    "out/associations/{target}/mapped.tsv"
  params:
    "/tmp/{target}_map_back_" + username
  conda: "envs/pyseer.yaml"
  log: "out/logs/map_back_{target}.log"
  shell:
    """
    rm -rf {params} || true
    mkdir -p {params}
    echo -e "strain\\tunitig\\tcontig\\tstart\\tend\\tstrand\\tupstream\\tgene\\tdownstream" > {output}
    python workflow/scripts/map_back.py {input.unitigs} {input.fasta} --tmp-prefix {params} --gff {input.gff} --print-details --pangenome {input.pangenome} >> {output} 2>> {log}
    """

rule run_map_back_all:
  input:
    unitigs="out/associations/{target}/unitigs.tsv",
    reffastadir=os.path.join(config["references_dir"], "fastas"),
    refgffdir=os.path.join(config["references_dir"], "gffs"),
  output:
    "out/associations/{target}/mapped_all.tsv"
  params:
    "/tmp/{target}_map_back_all_" + username
  conda: "envs/pyseer.yaml"
  log: "out/logs/map_back_all_{target}.log"
  shell:
    """
    rm -rf {params} || true
    mkdir -p {params}
    echo -e "strain\\tunitig\\tcontig\\tstart\\tend\\tstrand\\tupstream\\tgene\\tdownstream" > {params}/mapped.tsv
    python workflow/scripts/map_back.py {input.unitigs} {input.reffastadir} --tmp-prefix {params} --gff {input.refgffdir} --print-details >> {params}/mapped.tsv 2> {log}
    python workflow/scripts/make_skyline.py {input.unitigs} {params}/mapped.tsv > {output} 2>> {log}
    """

rule manhattan_plots:
  input:
    expand("out/associations/{target}/manhattan.png",
           target=config["targets"])

rule run_manhattan_plot:
  input:
    mapped="out/associations/{target}/mapped_all.tsv",
    patterns="out/associations/{target}/unitigs_patterns.txt"
  output: "out/associations/{target}/manhattan.png"
  params: config["enrichment_reference"]
  conda: "envs/pyseer.yaml"
  log: "out/logs/manhattan_plot_{target}.log"
  shell:
    """
    python workflow/scripts/manhattan_plot.py {input} {params} {output}
    """

rule run_map_back_wg:
  input:
    unitigs="out/wg/{target}/{model}.tsv",
    fasta=config["mash_input"],
    gff=config["panaroo_input"],
    pangenome=config['pangenome_csv']
  output:
    "out/wg/{target}/mapped_{model}.tsv"
  params:
    "/tmp/{target}_{model}_map_back_" + username
  conda: "envs/pyseer.yaml"
  log: "out/logs/map_back_{model}_{target}.log"
  shell:
    """
    rm -rf {params} || true
    mkdir -p {params}
    echo -e "strain\\tunitig\\tcontig\\tstart\\tend\\tstrand\\tupstream\\tgene\\tdownstream" > {output}
    python workflow/scripts/map_back.py {input.unitigs} {input.fasta} --tmp-prefix {params} --gff {input.gff} --print-details --pangenome {input.pangenome} >> {output} 2>> {log}
    """

rule map_summary:
  input:
    expand("out/associations/{target}/summary.tsv",
           target=config["targets"]),
    expand("out/associations/{target}/summary_panfeed.tsv",
           target=config["targets"]),
    expand("out/wg/{target}/summary_{model}.tsv",
           target=config["targets"],
           model=["ridge", "lasso"]),

rule map_summary_fig:
  input:
    mapped=expand("out/associations/{target}/mapped.svg",
                  target=config["targets"]),

rule run_map_summary:
  input:
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    filtered="out/associations/{target}/unitigs_filtered.tsv",
    pangenome=config["pangenome"],
    pangenome2=config["pangenome_csv"],
    mapped="out/associations/{target}/mapped.tsv",
  output:
    summary="out/associations/{target}/summary.tsv"
  params:
    d=config["references_gffs"],
    r=config["summary_references"]
  log: "out/logs/map_summary_{target}.log"
  shell:
    """
    python workflow/scripts/mapped_summary.py {input.mapped} \
           {input.phenotypes} {wildcards.target} {input.filtered} \
           --pangenome {input.pangenome} \
           --pangenome-genes {input.pangenome2} \
           --length 30 --minimum-hits 9 --maximum-genes 10 \
           {params.r} \
           --gff-dir {params.d} \
           --unique --sort avg-lrt-pvalue \
           > {output.summary} 2> {log} || true
    """

rule run_map_summary_panfeed:
  input:
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    pangenome=config["pangenome"],
    pangenome2=config["pangenome_csv"],
    mapped="out/associations/{target}/panfeed_kmers.tsv.gz",
  output:
    summary="out/associations/{target}/summary_panfeed.tsv"
  params:
    d=config["references_gffs"],
    r=config["summary_references"]
  log: "out/logs/map_summary_panfeed_{target}.log"
  shell:
    """
    python workflow/scripts/mapped_summary.py {input.mapped} \
           {input.phenotypes} {wildcards.target} /dev/null \
           --pangenome {input.pangenome} \
           --pangenome-genes {input.pangenome2} \
           --minimum-hits 9 --maximum-genes 10 \
           {params.r} \
           --gff-dir {params.d} \
           --unique --sort avg-lrt-pvalue \
           --panfeed \
           > {output.summary} 2> {log} || true
    """

rule run_map_summary_wg:
  input:
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    filtered="out/wg/{target}/{model}.tsv",
    pangenome=config["pangenome"],
    pangenome2=config["pangenome_csv"],
    mapped="out/wg/{target}/mapped_{model}.tsv",
  output:
    summary="out/wg/{target}/summary_{model}.tsv"
  params:
    d=config["references_gffs"],
    r=config["summary_references"]
  log: "out/logs/map_summary_{model}_{target}.log"
  shell:
    """
    python workflow/scripts/mapped_summary.py {input.mapped} \
           {input.phenotypes} {wildcards.target} {input.filtered} \
           --pangenome {input.pangenome} \
           --pangenome-genes {input.pangenome2} \
           --length 30 --minimum-hits 9 --maximum-genes 10 \
           {params.r} \
           --gff-dir {params.d} \
           --unique --sort avg-beta \
           > {output.summary} || true
    """

rule run_map_summary_fig:
  input:
    config["tree"],
    "out/associations/inputs/lineages.tsv",
    "out/associations/{target}/mapped.tsv"
  output:
    "out/associations/{target}/mapped.svg"
  log: "out/logs/map_summary_fig_{target}.log"
  conda: "../envs/pyseer.yaml"
  shell:
    """
    python workflow/scripts/unitigs2fig.py {input} {output}
    """

rule annotate_summary:
  input:
    expand("out/associations/{target}/annotated_summary.tsv",
           target=config["targets"]),
    expand("out/associations/{target}/annotated_rare_summary.tsv",
           target=config["targets"]),
    expand("out/associations/{target}/annotated_gpa_summary.tsv",
           target=config["targets"]),
    expand("out/associations/{target}/annotated_panfeed_summary.tsv",
           target=config["targets"]),
    expand("out/wg/{target}/annotated_summary_{model}.tsv",
           target=config["targets"],
           model=["ridge", "lasso"]),

rule run_annotate_summary:
  input:
    summary="out/associations/{target}/summary.tsv",
    pangenome=config["pangenome_csv"],
    genes=config["pangenome_genes"]
  output:
    "out/associations/{target}/annotated_summary.tsv"
  params:
    emapper_data=config["emapper"],
    emapper_base="out/associations/{target}/summary",
    sample="out/associations/{target}/sample.faa",
    annotations="out/associations/{target}/summary.emapper.annotations",
    r=config["annotation_references"]
  threads: 8
  conda: "envs/eggnog-mapper.yaml"
  log: "out/logs/annotate_{target}.log"
  shell:
    """
    python workflow/scripts/sample_pangenome.py {input.pangenome} {input.genes} \
               {params.r} \
               --groups {input.summary} > {params.sample} 2> {log} && \
    if [ ! -e {params.emapper_data} ] || ( [ -L {params.emapper_data} ] && [ ! -e {params.emapper_data} ] ); then \
      echo "eggnog-mapper database missing" >> {log}; \
      exit 1;
    fi
    emapper.py -i {params.sample} -o {params.emapper_base} \
               --cpu {threads} --target_orthologs one2one --go_evidence all \
               --tax_scope Bacteria --pfam_realign none --override \
               --data_dir {params.emapper_data} 2>> {log} || touch {output} && \
    python workflow/scripts/enhance_summary.py {input.summary} {params.annotations} \
    > {output} 2>> {log}
    """

rule run_annotate_rare_summary:
  input:
    summary="out/associations/{target}/rare_summary.tsv",
    pangenome=config["pangenome_csv"],
    genes=config["pangenome_genes"]
  output:
    "out/associations/{target}/annotated_rare_summary.tsv"
  params:
    emapper_data=config["emapper"],
    emapper_base="out/associations/{target}/rare_summary",
    sample="out/associations/{target}/rare_sample.faa",
    annotations="out/associations/{target}/rare_summary.emapper.annotations",
    r=config["annotation_references"]
  threads: 8
  conda: "envs/eggnog-mapper.yaml"
  log: "out/logs/annotate_rare_{target}.log"
  shell:
    """
    python workflow/scripts/sample_pangenome.py {input.pangenome} {input.genes} \
               {params.r} \
               --groups {input.summary} > {params.sample} 2> {log} && \
    if [ ! -e {params.emapper_data} ] || ( [ -L {params.emapper_data} ] && [ ! -e {params.emapper_data} ] ); then \
      echo "eggnog-mapper database missing" >> {log}; \
      exit 1;
    fi
    emapper.py -i {params.sample} -o {params.emapper_base} \
               --cpu {threads} --target_orthologs one2one --go_evidence all \
               --tax_scope Bacteria --pfam_realign none --override \
               --data_dir {params.emapper_data} 2>> {log} || touch {output} && \
    python workflow/scripts/enhance_summary.py {input.summary} {params.annotations} \
    > {output} 2>> {log}
    """

rule run_annotate_gpa_summary:
  input:
    summary="out/associations/{target}/gpa_summary.tsv",
    pangenome=config["pangenome_csv"],
    genes=config["pangenome_genes"]
  output:
    "out/associations/{target}/annotated_gpa_summary.tsv"
  params:
    emapper_data=config["emapper"],
    emapper_base="out/associations/{target}/gpa_summary",
    sample="out/associations/{target}/gpa_sample.faa",
    annotations="out/associations/{target}/gpa_summary.emapper.annotations",
    r=config["annotation_references"]
  threads: 8
  conda: "envs/eggnog-mapper.yaml"
  log: "out/logs/annotate_gpa_{target}.log"
  shell:
    """
    python workflow/scripts/sample_pangenome.py {input.pangenome} {input.genes} \
               {params.r} \
               --groups {input.summary} > {params.sample} 2> {log} && \
    if [ ! -e {params.emapper_data} ] || ( [ -L {params.emapper_data} ] && [ ! -e {params.emapper_data} ] ); then \
      echo "eggnog-mapper database missing" >> {log}; \
      exit 1;
    fi
    emapper.py -i {params.sample} -o {params.emapper_base} \
               --cpu {threads} --target_orthologs one2one --go_evidence all \
               --tax_scope Bacteria --pfam_realign none --override \
               --data_dir {params.emapper_data} 2>> {log} || touch {output} && \
    python workflow/scripts/enhance_summary.py {input.summary} {params.annotations} \
    > {output} 2>> {log}
    """

rule run_annotate_panfeed_summary:
  input:
    summary="out/associations/{target}/summary_panfeed.tsv",
    pangenome=config["pangenome_csv"],
    genes=config["pangenome_genes"]
  output:
    "out/associations/{target}/annotated_panfeed_summary.tsv"
  params:
    emapper_data=config["emapper"],
    emapper_base="out/associations/{target}/panfeed_summary",
    sample="out/associations/{target}/panfeed_sample.faa",
    annotations="out/associations/{target}/panfeed_summary.emapper.annotations",
    r=config["annotation_references"]
  threads: 8
  conda: "envs/eggnog-mapper.yaml"
  log: "out/logs/annotate_panfeed_{target}.log"
  shell:
    """
    python workflow/scripts/sample_pangenome.py {input.pangenome} {input.genes} \
               {params.r} \
               --groups {input.summary} > {params.sample} 2> {log} && \
    if [ ! -e {params.emapper_data} ] || ( [ -L {params.emapper_data} ] && [ ! -e {params.emapper_data} ] ); then \
      echo "eggnog-mapper database missing" >> {log}; \
      exit 1;
    fi
    emapper.py -i {params.sample} -o {params.emapper_base} \
               --cpu {threads} --target_orthologs one2one --go_evidence all \
               --tax_scope Bacteria --pfam_realign none --override \
               --data_dir {params.emapper_data} 2>> {log} || touch {output} && \
    python workflow/scripts/enhance_summary.py {input.summary} {params.annotations} \
    > {output} 2>> {log}
    """

rule run_annotate_summary_wg:
  input:
    summary="out/wg/{target}/summary_{model}.tsv",
    pangenome=config["pangenome_csv"],
    genes=config["pangenome_genes"]
  output:
    "out/wg/{target}/annotated_summary_{model}.tsv"
  params:
    emapper_data=config["emapper"],
    emapper_base="out/wg/{target}/summary_{model}",
    sample="out/wg/{target}/sample_{model}.faa",
    annotations="out/wg/{target}/summary_{model}.emapper.annotations",
    r=config["annotation_references"]
  threads: 8
  conda: "envs/eggnog-mapper.yaml"
  log: "out/logs/annotate_{model}_{target}.log"
  shell:
    """
    python workflow/scripts/sample_pangenome.py {input.pangenome} {input.genes} \
               {params.r} \
               --groups {input.summary} > {params.sample} 2> {log} && \
    if [ ! -e {params.emapper_data} ] || ( [ -L {params.emapper_data} ] && [ ! -e {params.emapper_data} ] ); then \
      echo "eggnog-mapper database missing" >> {log}; \
      exit 1;
    fi
    emapper.py -i {params.sample} -o {params.emapper_base} \
               --cpu {threads} --target_orthologs one2one --go_evidence all \
               --tax_scope Bacteria --pfam_realign none --override \
               --data_dir {params.emapper_data} 2>> {log} || touch {output} && \
    python workflow/scripts/enhance_summary.py {input.summary} {params.annotations} \
    > {output} 2>> {log}
    """

rule annotate_reference:
  input:
    pangenome=config["pangenome_csv"],
    genes=config["pangenome_genes"]
  output: config["annotated_reference"]
  params:
    emapper_data=config["emapper"],
    emapper_base="out/reference",
    sample="out/reference.faa",
    annotations="out/reference.emapper.annotations",
    r=config["enrichment_reference"]
  threads: 8
  conda: "envs/eggnog-mapper.yaml"
  log: "out/logs/annotate_reference.log"
  shell:
    """
    python workflow/scripts/sample_pangenome.py {input.pangenome} {input.genes} \
               --focus-strain {params.r} --only-focus \
               > {params.sample} 2> {log} && \
    if [ ! -e {params.emapper_data} ] || ( [ -L {params.emapper_data} ] && [ ! -e {params.emapper_data} ] ); then \
      echo "eggnog-mapper database missing" >> {log}; \
      exit 1;
    fi
    emapper.py -i {params.sample} -o {params.emapper_base} \
               --cpu {threads} --target_orthologs one2one --go_evidence all \
               --tax_scope Bacteria --pfam_realign none --override \
               --data_dir {params.emapper_data} 2>> {log} || touch {output} && \
    python workflow/scripts/enhance_summary.py /dev/null {params.annotations} --no-summary \
    > {output} 2>> {log}
    """

rule download_obo:
  output: config["go_obo"]
  shell: "wget -O {output} 'http://purl.obolibrary.org/obo/go/go-basic.obo'"

rule enrichment:
  input:
    expand('out/associations/{target}/COG.tsv',
           target=config["targets"]),
    expand('out/associations/{target}/GO.tsv',
           target=config["targets"]),
    expand('out/associations/{target}/KEGG.tsv',
           target=config["targets"]),
    expand('out/associations/{target}/COG_{kind}.tsv',
           target=config["targets"],
           kind=['gpa', 'rare', 'panfeed']),
    expand('out/associations/{target}/GO_{kind}.tsv',
           target=config["targets"],
           kind=['gpa', 'rare', 'panfeed']),
    expand('out/associations/{target}/KEGG_{kind}.tsv',
           target=config["targets"],
           kind=['gpa', 'rare', 'panfeed']),
    expand("out/wg/{target}/COG_{model}.tsv",
           target=config["targets"],
           model=["ridge", "lasso"]),
    expand("out/wg/{target}/GO_{model}.tsv",
           target=config["targets"],
           model=["ridge", "lasso"]),
    expand("out/wg/{target}/KEGG_{model}.tsv",
           target=config["targets"],
           model=["ridge", "lasso"]),

rule run_enrich:
  input:
    sample="out/associations/{target}/annotated_summary.tsv",
    reference=config["annotated_reference"],
    obo=config["go_obo"]
  output:
    cog="out/associations/{target}/COG.tsv",
    go="out/associations/{target}/GO.tsv",
    kegg="out/associations/{target}/KEGG.tsv",
  conda: "envs/enrich.yaml"
  log: "out/logs/enrich_{target}.log"
  shell:
    """
    python workflow/scripts/functional_enrichment.py {input.sample} \
            {input.reference} {input.obo} {output} 2> {log}
    """

rule run_enrich_alt:
  input:
    sample="out/associations/{target}/annotated_{kind}_summary.tsv",
    reference=config["annotated_reference"],
    obo=config["go_obo"]
  output:
    cog="out/associations/{target}/COG_{kind}.tsv",
    go="out/associations/{target}/GO_{kind}.tsv",
    kegg="out/associations/{target}/KEGG_{kind}.tsv"
  conda: "envs/enrich.yaml"
  log: "out/logs/enrich_{target}_{kind}.log"
  shell:
    """
    python workflow/scripts/functional_enrichment.py {input.sample} \
            {input.reference} {input.obo} {output} 2> {log}
    """

rule run_enrich_wg:
  input:
    sample="out/wg/{target}/annotated_summary_{model}.tsv",
    reference=config["annotated_reference"],
    obo=config["go_obo"]
  output:
    cog="out/wg/{target}/COG_{model}.tsv",
    go="out/wg/{target}/GO_{model}.tsv",
    kegg="out/wg/{target}/KEGG_{model}.tsv"
  conda: "envs/enrich.yaml"
  log: "out/logs/enrich_{target}_{model}.log"
  shell:
    """
    python workflow/scripts/functional_enrichment.py {input.sample} \
            {input.reference} {input.obo} {output} 2> {log}
    """

rule enrichment_plots:
  input:
    expand("out/associations/{target}/COG.png", target=config["targets"]),
    expand("out/associations/{target}/GO.png", target=config["targets"]),
    expand("out/associations/{target}/KEGG.png", target=config["targets"]),
    expand('out/associations/{target}/COG_{kind}.png',
           target=config["targets"],
           kind=['gpa', 'rare', 'panfeed']),
    expand('out/associations/{target}/GO_{kind}.png',
           target=config["targets"],
           kind=['gpa', 'rare', 'panfeed']),
    expand('out/associations/{target}/KEGG_{kind}.png',
           target=config["targets"],
           kind=['gpa', 'rare', 'panfeed']),
    expand("out/wg/{target}/COG_{model}.png", target=config["targets"],
                                              model=["ridge", "lasso"]),
    expand("out/wg/{target}/GO_{model}.png", target=config["targets"],
                                              model=["ridge", "lasso"]),
    expand("out/wg/{target}/KEGG_{model}.png", target=config["targets"],
                                              model=["ridge", "lasso"]),

rule run_enrichment_plots:
  input:
    cog="out/associations/{target}/COG.tsv",
    go="out/associations/{target}/GO.tsv",
    kegg="out/associations/{target}/KEGG.tsv"
  output:
    cog_plot="out/associations/{target}/COG.png",
    go_plot="out/associations/{target}/GO.png",
    kegg_plot="out/associations/{target}/KEGG.png"
  conda: "envs/pyseer.yaml"
  log: "out/logs/enrich_plots_{target}.log"
  shell:
    """
    python3 workflow/scripts/enrich_plots.py {input.cog} {output.cog_plot} {input.go} \
           {output.go_plot} {input.kegg} {output.kegg_plot} 2> {log}
    """

rule run_enrichment_plots_alt:
  input:
    cog="out/associations/{target}/COG_{kind}.tsv",
    go="out/associations/{target}/GO_{kind}.tsv",
    kegg="out/associations/{target}/KEGG_{kind}.tsv"
  output:
    cog_plot="out/associations/{target}/COG_{kind}.png",
    go_plot="out/associations/{target}/GO_{kind}.png",
    kegg_plot="out/associations/{target}/KEGG_{kind}.png"
  conda: "envs/pyseer.yaml"
  log: "out/logs/enrich_plots_{target}_{kind}.log"
  shell:
    """
    python3 workflow/scripts/enrich_plots.py {input.cog} {output.cog_plot} {input.go} \
           {output.go_plot} {input.kegg} {output.kegg_plot} 2> {log}
    """

rule run_enrichment_plots_wg:
  input:
    cog="out/wg/{target}/COG_{model}.tsv",
    go="out/wg/{target}/GO_{model}.tsv",
    kegg="out/wg/{target}/KEGG_{model}.tsv"
  output:
    cog_plot="out/wg/{target}/COG_{model}.png",
    go_plot="out/wg/{target}/GO_{model}.png",
    kegg_plot="out/wg/{target}/KEGG_{model}.png"
  conda: "envs/pyseer.yaml"
  log: "out/logs/enrich_plots_{target}_{model}.log"
  shell:
    """
    python3 workflow/scripts/enrich_plots.py {input.cog} {output.cog_plot} {input.go} \
           {output.go_plot} {input.kegg} {output.kegg_plot} 2> {log}
    """

rule panfeed_kmers:
  input:
    pangenome=config["pangenome"],
    gff=config["panaroo_input"],
    fasta=config["mash_input"],
  output:
    config["panfeed_patterns"],
    config["panfeed_conversion"],
  params:
    input=config["pangenome_csv"],
    outdir=config["panfeed_dir"]
  threads: 4
  conda: "envs/panfeed.yaml"
  log: "out/logs/panfeed.log"
  shell:
    """
    rm -rf {params.outdir} || true && \
    panfeed \
        --gff {input.gff} \
        --fasta {input.fasta} \
        -o {params.outdir} \
        -p {params.input} \
        --upstream 250 --downstream 100 \
        --no-filter \
        -v \
        --cores {threads} 2> {log}
    """

rule panfeed_first_pass:
  input:
    expand('out/associations/{target}/panfeed.tsv',
           target=config["targets"])

rule run_panfeed:
  input:
    kmers=config["panfeed_patterns"],
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    similarity=os.path.join(config["association_inputs"], "{target}/similarity.tsv"),
    distances=os.path.join(config["association_inputs"], "{target}/distances.tsv"),
    lineages=os.path.join(config["association_inputs"], "{target}/lineages.tsv"),
    patterns="out/associations/{target}/unitigs_patterns.txt",
  output:
    p="out/associations/{target}/panfeed.tsv",
    p_f="out/associations/{target}/panfeed_filtered.tsv",
  params:
    covariates=lambda wildcards: config.get("covariates", {wildcards.target: ''})[wildcards.target]
  threads: 2
  conda: "envs/pyseer.yaml"
  log: "out/logs/panfeed_{target}.log"
  shell:
    """
    pyseer --phenotypes {input.phenotypes} \
           --phenotype-column {wildcards.target} \
           --pres {input.kmers} \
           --similarity {input.similarity} \
           --lmm --uncompressed \
           --output-patterns out/associations/{wildcards.target}/panfeed_patterns.txt \
           --cpu {threads} \
           {params.covariates} \
           > {output.p} 2> {log}
    cat <(head -1 {output.p}) <(LC_ALL=C awk -v pval=$(python workflow/scripts/count_patterns.py --threshold {input.patterns}) '$4<pval {{print $0}}' {output.p}) > {output.p_f}
    """

rule annotate_panfeed_small:
  input:
    expand("out/associations/{target}/panfeed_kmers.tsv.gz",
           target=config["targets"])

rule run_annotate_panfeed_small:
  input:
    associations="out/associations/{target}/panfeed.tsv",
    kmers=config["panfeed_conversion"],
    patterns="out/associations/{target}/unitigs_patterns.txt",
  output:
    "out/associations/{target}/panfeed_kmers.tsv.gz"
  log: "out/logs/panfeed_annotate_small_{target}.log"
  shell:
    """
    python workflow/scripts/combine_panfeed.py \
           {input.associations} {input.kmers} \
           --threshold $(python workflow/scripts/count_patterns.py --threshold {input.patterns}) \
           | gzip > {output} 2> {log}
    """

rule panfeed:
  input:
    expand("out/associations/{target}/panfeed_annotated_kmers.tsv.gz",
           target=config["targets"]),
    expand("out/associations/{target}/panfeed_plots/plots.done",
           target=config["targets"])

rule panfeed_downstream:
  input:
    phenotypes=os.path.join(config["association_inputs"], "{target}/phenotypes.tsv"),
    pangenome=config["pangenome"],
    patterns="out/associations/{target}/unitigs_patterns.txt",
    panfeed="out/associations/{target}/panfeed.tsv",
    panfeed_conversion=config["panfeed_conversion"],
    gff=config["panaroo_input"],
    fasta=config["mash_input"],
    samples=config["unitigs_input"]
  output:
    kmers="out/associations/{target}/panfeed_annotated_kmers.tsv.gz",
    plots="out/associations/{target}/panfeed_plots/plots.done"
  params:
    input=config["pangenome_csv"],
    outdir="out/associations/{target}/panfeed_second_pass",
    plotsdir="out/associations/{target}/panfeed_plots",
    clusters="out/associations/{target}/panfeed_clusters.txt",
    targets="out/associations/{target}/panfeed_targets.txt",
    k2h="out/associations/{target}/panfeed_second_pass/kmers_to_hashes.tsv",
    k="out/associations/{target}/panfeed_second_pass/kmers.tsv",
  threads: 4
  conda: "envs/panfeed.yaml"
  log: "out/logs/panfeed_second_pass_{target}.log"
  shell:
    """
    panfeed-get-clusters \
        -a {input.panfeed} \
        -p {input.panfeed_conversion} \
        -t $(python workflow/scripts/count_patterns.py --threshold {input.patterns}) \
        > {params.clusters} 2> {log} && \
    rm -rf {params.outdir} 2>> {log} || true && \
    tail -n+2 {input.samples} | awk '{{print $1}}' | sort | uniq > {params.targets} && \
    panfeed \
        --gff {input.gff} \
        --fasta {input.fasta} \
        -o {params.outdir} \
        -p {params.input} \
        --upstream 250 --downstream 100 \
        --no-filter \
        -v \
        --genes {params.clusters} \
        --targets {params.targets} \
        --cores {threads} 2>> {log} && \
    panfeed-get-kmers \
        -a {input.panfeed} \
        -p {params.k2h} \
        -k {params.k} 2>> {log} \
        | gzip > {output.kmers} && \
    rm -rf {params.outdir} && \
    mkdir -p {params.plotsdir} && \
    panfeed-plot -k $(realpath {output.kmers}) \
        -p $(realpath {input.phenotypes}) \
        --phenotype-column {wildcards.target} \
        -t $(python workflow/scripts/count_patterns.py \
        --threshold {input.patterns}) \
        --output-directory {params.plotsdir} 2>> {log} && \
    touch {output.plots} 2>> {log}
    """

